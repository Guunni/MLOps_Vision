"""
PatchCore ëª¨ë¸ ê´€ë¦¬ ë° ê²°ê³¼ ë¶„ì„ ì‹œìŠ¤í…œ
í•™ìŠµëœ ëª¨ë¸ì˜ ì €ì¥, ë¡œë“œ, ë¶„ì„, ë°°í¬ë¥¼ ê´€ë¦¬í•˜ëŠ” ì‹œìŠ¤í…œ
"""

import os
import shutil
import zipfile
import json
import pickle
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
import logging
import pandas as pd
import numpy as np

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PatchCoreModelManager:
    """
    PatchCore ëª¨ë¸ì˜ ì „ì²´ ìƒëª…ì£¼ê¸°ë¥¼ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤
    
    ì£¼ìš” ê¸°ëŠ¥:
    1. í•™ìŠµ ì™„ë£Œëœ ëª¨ë¸ ìë™ íƒì§€
    2. ëª¨ë¸ íŒŒì¼ ê²€ì¦ ë° ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
    3. ëª¨ë¸ ì••ì¶• ë° ì•„ì¹´ì´ë¸Œ ìƒì„±
    4. ëª¨ë¸ ì„±ëŠ¥ ë¶„ì„ ë° ë¹„êµ
    5. ëª¨ë¸ ë°°í¬ ì¤€ë¹„
    """
    
    def __init__(self, results_dir: str = None, models_archive_dir: str = None):
        """
        ëª¨ë¸ ê´€ë¦¬ìë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        
        Args:
            results_dir: í•™ìŠµ ê²°ê³¼ê°€ ì €ì¥ëœ ë””ë ‰í† ë¦¬
            models_archive_dir: ëª¨ë¸ ì•„ì¹´ì´ë¸Œë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬
        """
        if results_dir is None:
            self.results_dir = Path.cwd().parent / "models"
        else:
            self.results_dir = Path(results_dir)
        
        if models_archive_dir is None:
            self.models_archive_dir = Path.cwd().parent / "models" / "archives"
        else:
            self.models_archive_dir = Path(models_archive_dir)
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.results_dir.mkdir(parents=True, exist_ok=True)
        self.models_archive_dir.mkdir(parents=True, exist_ok=True)
        
        # ëª¨ë¸ íƒì§€ë¥¼ ìœ„í•œ í•„ìˆ˜ íŒŒì¼ë“¤
        self.required_model_files = [
            "patchcore_params.pkl",
            "nnscorer_search_index.faiss"
        ]
        
        logger.info(f"ëª¨ë¸ ê´€ë¦¬ì ì´ˆê¸°í™”ë¨")
        logger.info(f"  - ê²°ê³¼ ë””ë ‰í† ë¦¬: {self.results_dir}")
        logger.info(f"  - ì•„ì¹´ì´ë¸Œ ë””ë ‰í† ë¦¬: {self.models_archive_dir}")
    
    def discover_trained_models(self) -> List[Dict[str, Any]]:
        """
        ê²°ê³¼ ë””ë ‰í† ë¦¬ì—ì„œ í•™ìŠµ ì™„ë£Œëœ ëª¨ë¸ë“¤ì„ ìë™ìœ¼ë¡œ íƒì§€í•©ë‹ˆë‹¤.
        
        Returns:
            List[Dict]: ë°œê²¬ëœ ëª¨ë¸ë“¤ì˜ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        logger.info("ğŸ” í•™ìŠµëœ ëª¨ë¸ íƒì§€ ì¤‘...")
        
        discovered_models = []
        
        # patchcore_params.pkl íŒŒì¼ì„ ì°¾ì•„ì„œ ëª¨ë¸ ë””ë ‰í† ë¦¬ ì‹ë³„
        for pkl_file in self.results_dir.rglob("patchcore_params.pkl"):
            model_dir = pkl_file.parent
            
            # í•„ìˆ˜ íŒŒì¼ë“¤ì´ ëª¨ë‘ ìˆëŠ”ì§€ í™•ì¸
            model_info = self._analyze_model_directory(model_dir)
            
            if model_info["is_complete"]:
                discovered_models.append(model_info)
                logger.info(f"âœ… ì™„ì „í•œ ëª¨ë¸ ë°œê²¬: {model_info['model_name']}")
            else:
                logger.warning(f"âš ï¸ ë¶ˆì™„ì „í•œ ëª¨ë¸: {model_dir}")
                logger.warning(f"   ëˆ„ë½ëœ íŒŒì¼: {model_info['missing_files']}")
        
        logger.info(f"ì´ {len(discovered_models)}ê°œì˜ ì™„ì „í•œ ëª¨ë¸ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
        return discovered_models
    
    def _analyze_model_directory(self, model_dir: Path) -> Dict[str, Any]:
        """
        ëª¨ë¸ ë””ë ‰í† ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ìƒì„¸ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            model_dir: ë¶„ì„í•  ëª¨ë¸ ë””ë ‰í† ë¦¬
            
        Returns:
            Dict: ëª¨ë¸ ë¶„ì„ ê²°ê³¼
        """
        model_info = {
            "model_path": str(model_dir),
            "model_name": model_dir.name,
            "is_complete": True,
            "missing_files": [],
            "available_files": [],
            "metadata": {},
            "creation_time": None,
            "file_sizes": {}
        }
        
        # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        for required_file in self.required_model_files:
            file_path = model_dir / required_file
            if file_path.exists():
                model_info["available_files"].append(required_file)
                model_info["file_sizes"][required_file] = file_path.stat().st_size
                
                # ìƒì„± ì‹œê°„ ì—…ë°ì´íŠ¸ (ê°€ì¥ ìµœê·¼ íŒŒì¼ ê¸°ì¤€)
                file_mtime = datetime.fromtimestamp(file_path.stat().st_mtime)
                if model_info["creation_time"] is None or file_mtime > model_info["creation_time"]:
                    model_info["creation_time"] = file_mtime
            else:
                model_info["missing_files"].append(required_file)
                model_info["is_complete"] = False
        
        # ì¶”ê°€ íŒŒì¼ë“¤ë„ íƒì§€
        for file_path in model_dir.iterdir():
            if file_path.is_file() and file_path.name not in self.required_model_files:
                model_info["available_files"].append(file_path.name)
                model_info["file_sizes"][file_path.name] = file_path.stat().st_size
        
        # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹œë„
        try:
            model_info["metadata"] = self._extract_model_metadata(model_dir)
        except Exception as e:
            logger.warning(f"ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            model_info["metadata"] = {}
        
        return model_info
    
    def _extract_model_metadata(self, model_dir: Path) -> Dict[str, Any]:
        """
        ëª¨ë¸ ë””ë ‰í† ë¦¬ì—ì„œ ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            model_dir: ëª¨ë¸ ë””ë ‰í† ë¦¬
            
        Returns:
            Dict: ì¶”ì¶œëœ ë©”íƒ€ë°ì´í„°
        """
        metadata = {}
        
        # patchcore_params.pklì—ì„œ ì„¤ì • ì •ë³´ ì¶”ì¶œ
        params_file = model_dir / "patchcore_params.pkl"
        if params_file.exists():
            try:
                with open(params_file, 'rb') as f:
                    params = pickle.load(f)
                    metadata["model_params"] = self._sanitize_params(params)
            except Exception as e:
                logger.warning(f"íŒŒë¼ë¯¸í„° íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        
        # ì„±ëŠ¥ ë¡œê·¸ íŒŒì¼ ì°¾ê¸° ë° ë¶„ì„
        performance_data = self._find_performance_data(model_dir)
        if performance_data:
            metadata["performance"] = performance_data
        
        # ë””ë ‰í† ë¦¬ êµ¬ì¡° ë¶„ì„
        run_dir = model_dir.parent.parent  # results/log_group/run_X/model_dir
        if run_dir.exists():
            metadata["experiment_info"] = {
                "log_group": run_dir.parent.name,
                "run_id": run_dir.name,
                "full_path": str(run_dir)
            }
        
        return metadata
    
    def _sanitize_params(self, params: Any) -> Dict[str, Any]:
        """
        íŒŒë¼ë¯¸í„° ê°ì²´ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        """
        if hasattr(params, '__dict__'):
            return {k: str(v) for k, v in params.__dict__.items()}
        elif isinstance(params, dict):
            return {k: str(v) for k, v in params.items()}
        else:
            return {"raw_params": str(params)}
    
    def _find_performance_data(self, model_dir: Path) -> Optional[Dict[str, Any]]:
        """
        ëª¨ë¸ì˜ ì„±ëŠ¥ ë°ì´í„°ë¥¼ ì°¾ì•„ì„œ ë¶„ì„í•©ë‹ˆë‹¤.
        """
        performance_data = {}
        
        # results.csv íŒŒì¼ ì°¾ê¸°
        run_dir = model_dir.parent.parent
        results_csv = run_dir / "results.csv"
        
        if results_csv.exists():
            try:
                df = pd.read_csv(results_csv)
                if not df.empty:
                    # ë§ˆì§€ë§‰ í–‰ì˜ ì„±ëŠ¥ ì§€í‘œ ì¶”ì¶œ
                    last_row = df.iloc[-1]
                    performance_data = {
                        "image_auroc": float(last_row.get("image_auroc", 0)),
                        "pixel_auroc": float(last_row.get("pixel_auroc", 0)),
                        "image_aupro": float(last_row.get("image_aupro", 0)),
                        "pixel_aupro": float(last_row.get("pixel_aupro", 0))
                    }
            except Exception as e:
                logger.warning(f"ì„±ëŠ¥ ë°ì´í„° ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        return performance_data if performance_data else None
    
    def create_model_archive(self, model_info: Dict[str, Any], archive_name: str = None) -> Dict[str, Any]:
        """
        ëª¨ë¸ì„ ì••ì¶• ì•„ì¹´ì´ë¸Œë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            model_info: ì••ì¶•í•  ëª¨ë¸ ì •ë³´
            archive_name: ì•„ì¹´ì´ë¸Œ íŒŒì¼ ì´ë¦„ (Noneì´ë©´ ìë™ ìƒì„±)
            
        Returns:
            Dict: ì•„ì¹´ì´ë¸Œ ìƒì„± ê²°ê³¼
        """
        model_dir = Path(model_info["model_path"])
        
        if archive_name is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            archive_name = f"patchcore_{model_info['model_name']}_{timestamp}.zip"
        
        archive_path = self.models_archive_dir / archive_name
        
        try:
            logger.info(f"ğŸ“¦ ëª¨ë¸ ì•„ì¹´ì´ë¸Œ ìƒì„± ì¤‘: {archive_name}")
            
            with zipfile.ZipFile(archive_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                # ëª¨ë¸ íŒŒì¼ë“¤ ì¶”ê°€
                for file_name in model_info["available_files"]:
                    file_path = model_dir / file_name
                    if file_path.exists():
                        zipf.write(file_path, f"model/{file_name}")
                
                # ë©”íƒ€ë°ì´í„° JSON íŒŒì¼ ì¶”ê°€
                metadata_json = json.dumps(model_info, indent=2, default=str)
                zipf.writestr("metadata.json", metadata_json)
                
                # ì„±ëŠ¥ ê²°ê³¼ íŒŒì¼ì´ ìˆë‹¤ë©´ ì¶”ê°€
                run_dir = model_dir.parent.parent
                results_csv = run_dir / "results.csv"
                if results_csv.exists():
                    zipf.write(results_csv, "performance/results.csv")
            
            archive_size = archive_path.stat().st_size
            
            logger.info(f"âœ… ì•„ì¹´ì´ë¸Œ ìƒì„± ì™„ë£Œ: {archive_path}")
            logger.info(f"   íŒŒì¼ í¬ê¸°: {archive_size / 1024 / 1024:.2f} MB")
            
            return {
                "success": True,
                "archive_path": str(archive_path),
                "archive_name": archive_name,
                "archive_size": archive_size,
                "included_files": model_info["available_files"]
            }
            
        except Exception as e:
            logger.error(f"âŒ ì•„ì¹´ì´ë¸Œ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def load_model_for_inference(self, model_path: str) -> Optional[Any]:
        """
        ì¶”ë¡ ì„ ìœ„í•´ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.
        
        Args:
            model_path: ëª¨ë¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            
        Returns:
            ë¡œë“œëœ ëª¨ë¸ ê°ì²´ (ì‹¤íŒ¨ì‹œ None)
        """
        model_dir = Path(model_path)
        
        try:
            logger.info(f"ğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘: {model_dir}")
            
            # PatchCore ëª¨ë¸ ë¡œë”©ì„ ìœ„í•œ ì‹œìŠ¤í…œ ê²½ë¡œ ì„¤ì •
            import sys
            patchcore_src = Path.cwd().parent / "patchcore-inspection" / "src"
            if str(patchcore_src) not in sys.path:
                sys.path.insert(0, str(patchcore_src))
            
            # PatchCore ëª¨ë“ˆ import
            import patchcore.patchcore
            import patchcore.utils
            
            # ëª¨ë¸ íŒŒë¼ë¯¸í„° ë¡œë“œ
            params_file = model_dir / "patchcore_params.pkl"
            with open(params_file, 'rb') as f:
                model_params = pickle.load(f)
            
            # FAISS ì¸ë±ìŠ¤ ë¡œë“œ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” ë³µì¡í•œ ë¡œë”© ê³¼ì •ì´ í•„ìš”)
            faiss_file = model_dir / "nnscorer_search_index.faiss"
            
            logger.info("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
            
            # ì‹¤ì œ PatchCore ê°ì²´ ë°˜í™˜ (êµ¬í˜„ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ)
            return {
                "model_params": model_params,
                "faiss_index_path": str(faiss_file),
                "model_dir": str(model_dir)
            }
            
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            return None
    
    def compare_models(self, model_list: List[Dict[str, Any]]) -> pd.DataFrame:
        """
        ì—¬ëŸ¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë¹„êµí•©ë‹ˆë‹¤.
        
        Args:
            model_list: ë¹„êµí•  ëª¨ë¸ë“¤ì˜ ì •ë³´ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            DataFrame: ëª¨ë¸ ë¹„êµ ê²°ê³¼
        """
        comparison_data = []
        
        for model_info in model_list:
            row = {
                "model_name": model_info["model_name"],
                "creation_time": model_info["creation_time"],
                "total_size_mb": sum(model_info["file_sizes"].values()) / 1024 / 1024
            }
            
            # ì„±ëŠ¥ ì§€í‘œ ì¶”ê°€
            if "performance" in model_info["metadata"]:
                perf = model_info["metadata"]["performance"]
                row.update({
                    "image_auroc": perf.get("image_auroc", None),
                    "pixel_auroc": perf.get("pixel_auroc", None),
                    "image_aupro": perf.get("image_aupro", None),
                    "pixel_aupro": perf.get("pixel_aupro", None)
                })
            
            # ëª¨ë¸ íŒŒë¼ë¯¸í„° ì¶”ê°€
            if "model_params" in model_info["metadata"]:
                params = model_info["metadata"]["model_params"]
                # ì£¼ìš” íŒŒë¼ë¯¸í„°ë“¤ë§Œ ì¶”ì¶œ
                for key in ["backbone", "layers", "anomaly_scorer_num_nn", "sampling_ratio"]:
                    if key in params:
                        row[key] = params[key]
            
            comparison_data.append(row)
        
        df = pd.DataFrame(comparison_data)
        return df
    
    def get_best_model(self, models: List[Dict[str, Any]], metric: str = "image_auroc") -> Optional[Dict[str, Any]]:
        """
        ì§€ì •ëœ ë©”íŠ¸ë¦­ ê¸°ì¤€ìœ¼ë¡œ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì„ ì°¾ìŠµë‹ˆë‹¤.
        
        Args:
            models: ëª¨ë¸ ë¦¬ìŠ¤íŠ¸
            metric: ë¹„êµ ê¸°ì¤€ ë©”íŠ¸ë¦­
            
        Returns:
            Dict: ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì •ë³´ (ì—†ìœ¼ë©´ None)
        """
        best_model = None
        best_score = -1
        
        for model in models:
            if "performance" in model["metadata"]:
                score = model["metadata"]["performance"].get(metric, -1)
                if score > best_score:
                    best_score = score
                    best_model = model
        
        return best_model
    
    def cleanup_old_models(self, keep_count: int = 5) -> int:
        """
        ì˜¤ë˜ëœ ëª¨ë¸ë“¤ì„ ì •ë¦¬í•©ë‹ˆë‹¤.
        
        Args:
            keep_count: ë³´ê´€í•  ëª¨ë¸ ìˆ˜
            
        Returns:
            int: ì‚­ì œëœ ëª¨ë¸ ìˆ˜
        """
        models = self.discover_trained_models()
        
        if len(models) <= keep_count:
            logger.info(f"ì •ë¦¬í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. (í˜„ì¬ {len(models)}ê°œ, ë³´ê´€ ê¸°ì¤€ {keep_count}ê°œ)")
            return 0
        
        # ìƒì„± ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ìµœì‹ ìˆœ)
        models.sort(key=lambda x: x["creation_time"], reverse=True)
        
        # ë³´ê´€í•  ëª¨ë¸ë“¤ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ì‚­ì œ
        models_to_delete = models[keep_count:]
        deleted_count = 0
        
        for model in models_to_delete:
            try:
                model_path = Path(model["model_path"])
                if model_path.exists():
                    shutil.rmtree(model_path)
                    logger.info(f"ğŸ—‘ï¸ ëª¨ë¸ ì‚­ì œë¨: {model['model_name']}")
                    deleted_count += 1
            except Exception as e:
                logger.error(f"âŒ ëª¨ë¸ ì‚­ì œ ì‹¤íŒ¨: {model['model_name']} - {e}")
        
        logger.info(f"ì´ {deleted_count}ê°œì˜ ì˜¤ë˜ëœ ëª¨ë¸ì„ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.")
        return deleted_count

# ì‚¬ìš© ì˜ˆì‹œ ë° í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    # ëª¨ë¸ ê´€ë¦¬ì ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    manager = PatchCoreModelManager()
    
    # í•™ìŠµëœ ëª¨ë¸ë“¤ íƒì§€
    models = manager.discover_trained_models()
    
    if models:
        print(f"ğŸ“‹ ë°œê²¬ëœ ëª¨ë¸: {len(models)}ê°œ")
        
        for i, model in enumerate(models, 1):
            print(f"\n{i}. {model['model_name']}")
            print(f"   ê²½ë¡œ: {model['model_path']}")
            print(f"   ìƒì„±ì‹œê°„: {model['creation_time']}")
            print(f"   íŒŒì¼ ìˆ˜: {len(model['available_files'])}ê°œ")
            
            if "performance" in model["metadata"]:
                perf = model["metadata"]["performance"]
                print(f"   ì„±ëŠ¥: Image AUROC {perf.get('image_auroc', 'N/A')}")
        
        # ì²« ë²ˆì§¸ ëª¨ë¸ë¡œ ì•„ì¹´ì´ë¸Œ ìƒì„± ì˜ˆì‹œ
        print(f"\nğŸ“¦ ì²« ë²ˆì§¸ ëª¨ë¸ì˜ ì•„ì¹´ì´ë¸Œ ìƒì„± ì¤‘...")
        archive_result = manager.create_model_archive(models[0])
        
        if archive_result["success"]:
            print(f"âœ… ì•„ì¹´ì´ë¸Œ ìƒì„± ì™„ë£Œ: {archive_result['archive_name']}")
        else:
            print(f"âŒ ì•„ì¹´ì´ë¸Œ ìƒì„± ì‹¤íŒ¨: {archive_result['error']}")
            
    else:
        print("ğŸ“‚ ì•„ì§ í•™ìŠµëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("ë¨¼ì € PatchCore í•™ìŠµì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.")