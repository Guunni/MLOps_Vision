"""
MLOps Vision í”„ë¡œì íŠ¸ ì˜ì¡´ì„± ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸
í™˜ê²½ì— ë”°ë¼ ì ì ˆí•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ìë™ìœ¼ë¡œ ì„¤ì¹˜í•©ë‹ˆë‹¤.
"""

import subprocess
import sys
import argparse
import os
import platform
from pathlib import Path

def print_step(step_num, message):
    """ì„¤ì¹˜ ë‹¨ê³„ë¥¼ ëª…í™•í•˜ê²Œ í‘œì‹œ"""
    print(f"\n{'='*50}")
    print(f"ğŸ”¸ {step_num}ë‹¨ê³„: {message}")
    print(f"{'='*50}")

def get_os_info():
    """ìš´ì˜ì²´ì œ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    os_name = platform.system()
    os_version = platform.release()
    architecture = platform.machine()
    
    print(f"ìš´ì˜ì²´ì œ: {os_name} {os_version}")
    print(f"ì•„í‚¤í…ì²˜: {architecture}")
    
    return os_name, os_version, architecture

def check_nvidia_gpu():
    """
    nvidia-smië¥¼ í†µí•´ NVIDIA GPU ì¡´ì¬ ì—¬ë¶€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
    (PyTorch ì„¤ì¹˜ ì „ì— í™•ì¸í•˜ëŠ” ìš©ë„)
    """
    try:
        result = subprocess.run(['nvidia-smi'],
                               capture_output=True,
                               text=True,
                               timeout=10)
        if result.returncode == 0:
            print("âœ… NVIDIA GPU ê°ì§€ë¨")
            return True
        else:
            print("âŒ NVIDIA GPU ë¯¸ê°ì§€")
            return False
    except (subprocess.TimeoutExpired, FileNotFoundError):
        print("âŒ nvidia-smi ëª…ë ¹ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ (GPU ë¯¸ì„¤ì¹˜)")
        return False

def check_torch_cuda_after_install():
    """
    PyTorch ì„¤ì¹˜ í›„ CUDAê°€ ì‹¤ì œë¡œ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸í•©ë‹ˆë‹¤.
    """
    try:
        import torch
        if torch.cuda.is_available():
            print(f"âœ… PyTorch CUDA ì‚¬ìš© ê°€ëŠ¥ (GPU ê°œìˆ˜: {torch.cuda.device_count()})")
            for i in range(torch.cuda.device_count()):
                print(f"   - GPU {i}: {torch.cuda.get_device_name(i)}")
            return True
        else:
            print("âŒ PyTorchëŠ” ì„¤ì¹˜ë˜ì—ˆì§€ë§Œ CUDA ì‚¬ìš© ë¶ˆê°€")
            return False
    except ImportError:
        print("âŒ PyTorch ì„¤ì¹˜ ì‹¤íŒ¨ ë˜ëŠ” import ë¶ˆê°€")
        return False

def install_package(package_name):
    """ê°œë³„ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤."""
    print(f"ğŸ“¦ {package_name} ì„¤ì¹˜ ì¤‘...")
    try:
        subprocess.check_call([
            sys.executable, '-m', 'pip', 'install', package_name
        ])
        print(f"âœ… {package_name} ì„¤ì¹˜ ì™„ë£Œ")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ {package_name} ì„¤ì¹˜ ì‹¤íŒ¨: {e}")
        return False

def install_requirements(requirements_file):
    """requirements íŒŒì¼ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤."""
    if not os.path.exists(requirements_file):
        print(f"âš ï¸ {requirements_file} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê±´ë„ˆëœ€.")
        return False
    
    print(f"ğŸ“¦ {requirements_file} ì„¤ì¹˜ ì¤‘...")
    try:
        subprocess.check_call([
            sys.executable, '-m', 'pip', 'install', '-r', requirements_file
        ])
        print(f"âœ… {requirements_file} ì„¤ì¹˜ ì™„ë£Œ")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ {requirements_file} ì„¤ì¹˜ ì‹¤íŒ¨: {e}")
        print("ğŸ”„ ê°œë³„ íŒ¨í‚¤ì§€ ì„¤ì¹˜ë¡œ ì „í™˜í•©ë‹ˆë‹¤...")
        return False

def install_base_packages():
    """ê¸°ë³¸ íŒ¨í‚¤ì§€ë“¤ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤."""
    base_packages = [
        "numpy==2.1.2",
        "pillow==11.0.0", 
        "pandas>=2.0.0",
        "matplotlib>=3.7.0",
        "scikit-learn>=1.3.0",
        "opencv-python>=4.8.0",
        "tqdm>=4.65.0",
        "fastapi>=0.100.0",
        "uvicorn>=0.23.0"
    ]
    
    print("ğŸ“‹ ê¸°ë³¸ íŒ¨í‚¤ì§€ ëª©ë¡:")
    for pkg in base_packages:
        print(f"   - {pkg}")
    
    success_count = 0
    for package in base_packages:
        if install_package(package):
            success_count += 1
    
    print(f"ğŸ“Š ê¸°ë³¸ íŒ¨í‚¤ì§€: {success_count}/{len(base_packages)} ì„¤ì¹˜ ì™„ë£Œ")
    return success_count > 0

def install_pytorch_gpu():
    """PyTorch GPU ë²„ì „ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤."""
    pytorch_packages = [
        "torch==2.7.1+cu118", 
        "torchvision==0.22.1+cu118", 
        "torchaudio==2.7.1+cu118"
    ]
    
    print("ğŸ® PyTorch GPU ë²„ì „ ì„¤ì¹˜ ì¤‘...")
    
    # PyTorch index URL ì‚¬ìš©
    cmd = [
        sys.executable, '-m', 'pip', 'install'
    ] + pytorch_packages + [
        '--index-url', 'https://download.pytorch.org/whl/cu118'
    ]
    
    try:
        subprocess.check_call(cmd)
        print("âœ… PyTorch GPU ë²„ì „ ì„¤ì¹˜ ì™„ë£Œ")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ PyTorch GPU ì„¤ì¹˜ ì‹¤íŒ¨: {e}")
        return False

def install_pytorch_cpu():
    """PyTorch CPU ë²„ì „ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤."""
    pytorch_packages = [
        "torch>=2.0.0", 
        "torchvision>=0.15.0", 
        "torchaudio>=2.0.0"
    ]
    
    print("ğŸ–¥ï¸ PyTorch CPU ë²„ì „ ì„¤ì¹˜ ì¤‘...")
    
    success_count = 0
    for package in pytorch_packages:
        if install_package(package):
            success_count += 1
    
    return success_count == len(pytorch_packages)

def install_faiss_for_windows():
    """
    Windows í™˜ê²½ì—ì„œ faiss ì„¤ì¹˜ë¥¼ ì‹œë„í•©ë‹ˆë‹¤.
    """
    os_name = platform.system()
    if os_name != "Windows":
        return install_package("faiss-gpu>=1.7.0")
    
    print("ğŸªŸ Windows í™˜ê²½ì—ì„œ FAISS ì„¤ì¹˜ ì¤‘...")
    
    # 1. condaë¡œ faiss-gpu ì‹œë„
    try:
        print("   1ï¸âƒ£ condaë¥¼ í†µí•œ faiss-gpu ì„¤ì¹˜ ì‹œë„...")
        result = subprocess.run(['conda', 'install', '-c', 'conda-forge', 'faiss-gpu', '-y'],
                               capture_output=True, text=True, timeout=300)
        if result.returncode == 0:
            print("âœ… condaë¥¼ í†µí•œ faiss-gpu ì„¤ì¹˜ ì„±ê³µ")
            return True
    except (subprocess.TimeoutExpired, FileNotFoundError):
        print("   âŒ condaë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ì„¤ì¹˜ ì‹¤íŒ¨")
    
    # 2. pipë¡œ faiss-cpu ì‹œë„
    print("   2ï¸âƒ£ pipë¥¼ í†µí•œ faiss-cpu ì„¤ì¹˜ ì‹œë„...")
    return install_package("faiss-cpu>=1.7.0")

def install_ml_packages():
    """ë¨¸ì‹ ëŸ¬ë‹ ê´€ë ¨ íŒ¨í‚¤ì§€ë“¤ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤."""
    ml_packages = [
        "scikit-image>=0.21.0",
        "scipy>=1.11.0",
        "seaborn>=0.12.0"
    ]
    
    success_count = 0
    for package in ml_packages:
        if install_package(package):
            success_count += 1
    
    return success_count > 0

def install_dev_packages():
    """ê°œë°œ ë„êµ¬ë“¤ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤."""
    dev_packages = [
        "jupyter>=1.0.0",
        "jupyterlab>=4.0.0", 
        "black>=23.0.0",
        "pytest>=7.0.0",
        "plotly>=5.15.0",
        "GitPython>=3.0.0"
    ]
    
    success_count = 0
    for package in dev_packages:
        if install_package(package):
            success_count += 1
    
    print(f"ğŸ“Š ê°œë°œ ë„êµ¬: {success_count}/{len(dev_packages)} ì„¤ì¹˜ ì™„ë£Œ")
    return success_count > 0

def create_requirements_directory():
    """requirements ë””ë ‰í† ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    req_dir = Path('requirements')
    req_dir.mkdir(exist_ok=True)
    return req_dir

def main():
    parser = argparse.ArgumentParser(
        description='MLOps Vision í”„ë¡œì íŠ¸ ì˜ì¡´ì„± ì„¤ì¹˜',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python install_requirements.py              # ìë™ ê°ì§€ ì„¤ì¹˜
  python install_requirements.py --force-cpu  # ê°•ì œ CPU ë²„ì „
  python install_requirements.py --dev        # ê°œë°œ ë„êµ¬ í¬í•¨
  python install_requirements.py --dev --force-cpu  # CPU + ê°œë°œ ë„êµ¬
        """
    )
    parser.add_argument('--force-cpu', action='store_true', 
                       help='GPUê°€ ìˆì–´ë„ ê°•ì œë¡œ CPU ë²„ì „ì„ ì„¤ì¹˜')
    parser.add_argument('--dev', action='store_true', 
                       help='ê°œë°œìš© ë„êµ¬ë“¤ë„ í•¨ê»˜ ì„¤ì¹˜')
    parser.add_argument('--skip-base', action='store_true',
                       help='ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ê±´ë„ˆë›°ê¸° (ì´ë¯¸ ì„¤ì¹˜ëœ ê²½ìš°)')
    parser.add_argument('--use-files', action='store_true',
                       help='requirements íŒŒì¼ ì‚¬ìš© (ìˆëŠ” ê²½ìš°)')
    args = parser.parse_args()

    print("ğŸš€ MLOps Vision í”„ë¡œì íŠ¸ ì˜ì¡´ì„± ì„¤ì¹˜ ì‹œì‘")
    
    # ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥
    os_name, os_version, architecture = get_os_info()
    print(f"Python ë²„ì „: {sys.version}")
    print(f"pip ìœ„ì¹˜: {subprocess.check_output([sys.executable, '-m', 'pip', '--version'], text=True).strip()}")

    # requirements ë””ë ‰í† ë¦¬ í™•ì¸
    req_dir = create_requirements_directory()
    
    # 1ë‹¨ê³„: ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜
    if not args.skip_base:
        print_step(1, "ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜")
        
        if args.use_files and (req_dir / 'requirements_base.txt').exists():
            install_requirements(req_dir / 'requirements_base.txt')
        else:
            install_base_packages()
    else:
        print_step(1, "ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ê±´ë„ˆëœ€")

    # 2ë‹¨ê³„: PyTorch ì„¤ì¹˜ (CPU vs GPU)
    print_step(2, "PyTorch ì„¤ì¹˜")
    
    if args.force_cpu:
        print("ğŸ–¥ï¸ ê°•ì œ CPU ëª¨ë“œë¡œ ì„¤ì¹˜í•©ë‹ˆë‹¤.")
        pytorch_success = install_pytorch_cpu()
        use_gpu = False
    else:
        has_nvidia_gpu = check_nvidia_gpu()
        if has_nvidia_gpu:
            print("ğŸ® GPUê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. GPU ë²„ì „ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤.")
            pytorch_success = install_pytorch_gpu()
            use_gpu = True
        else:
            print("ğŸ–¥ï¸ GPU ë¯¸ê°ì§€ â†’ CPU ë²„ì „ ì„¤ì¹˜")
            pytorch_success = install_pytorch_cpu()
            use_gpu = False

    # 3ë‹¨ê³„: PyTorch ì„¤ì¹˜ í™•ì¸
    print_step(3, "PyTorch ì„¤ì¹˜ í™•ì¸")
    if pytorch_success:
        if use_gpu:
            cuda_available = check_torch_cuda_after_install()
            if not cuda_available:
                print("âš ï¸ GPU ë²„ì „ì„ ì„¤ì¹˜í–ˆì§€ë§Œ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                print("   CUDA ë“œë¼ì´ë²„ë‚˜ ëŸ°íƒ€ì„ì´ ì˜¬ë°”ë¥´ê²Œ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            try:
                import torch
                print(f"âœ… PyTorch CPU ë²„ì „ ì„¤ì¹˜ ì™„ë£Œ (ë²„ì „: {torch.__version__})")
            except ImportError:
                print("âŒ PyTorch ì„¤ì¹˜ í™•ì¸ ì‹¤íŒ¨")
    else:
        print("âŒ PyTorch ì„¤ì¹˜ì— ë¬¸ì œê°€ ìˆì—ˆìŠµë‹ˆë‹¤.")

    # 4ë‹¨ê³„: ì¶”ê°€ ML íŒ¨í‚¤ì§€ ì„¤ì¹˜
    print_step(4, "ë¨¸ì‹ ëŸ¬ë‹ íŒ¨í‚¤ì§€ ì„¤ì¹˜")
    install_ml_packages()
    
    # FAISS ë³„ë„ ì„¤ì¹˜
    print("ğŸ” FAISS ì„¤ì¹˜ ì¤‘...")
    install_faiss_for_windows()

    # 5ë‹¨ê³„: ê°œë°œ ë„êµ¬ ì„¤ì¹˜ (ì„ íƒì‚¬í•­)
    if args.dev:
        print_step(5, "ê°œë°œ ë„êµ¬ ì„¤ì¹˜")
        install_dev_packages()

    # 6ë‹¨ê³„: ì„¤ì¹˜ ì™„ë£Œ ìš”ì•½
    print_step("ì™„ë£Œ", "ì„¤ì¹˜ ìš”ì•½")
    print("ğŸ‰ ëª¨ë“  ì˜ì¡´ì„± ì„¤ì¹˜ ì™„ë£Œ!")
    print("\nğŸ“‹ ì„¤ì¹˜ëœ êµ¬ì„±:")
    print(f"   â€¢ ê¸°ë³¸ íŒ¨í‚¤ì§€: {'âœ…' if not args.skip_base else 'â­ï¸ ê±´ë„ˆëœ€'}")
    print(f"   â€¢ PyTorch: {'ğŸ® GPU ë²„ì „' if use_gpu else 'ğŸ–¥ï¸ CPU ë²„ì „'}")
    print(f"   â€¢ ê°œë°œ ë„êµ¬: {'âœ…' if args.dev else 'âŒ'}")
    
    print("\nğŸ”§ ë‹¤ìŒ ë‹¨ê³„:")
    print("   1. 'python -c \"import torch; print(torch.__version__)\"' ë¡œ ì„¤ì¹˜ í™•ì¸")
    if use_gpu:
        print("   2. 'python -c \"import torch; print(torch.cuda.is_available())\"' ë¡œ CUDA í™•ì¸")
    print("   3. 'python -c \"import numpy, pandas, cv2; print('ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ OK')\"' ë¡œ ì „ì²´ í™•ì¸")

if __name__ == '__main__':
    main()